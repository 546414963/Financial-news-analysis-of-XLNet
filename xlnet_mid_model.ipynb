{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d872094",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siger\\.conda\\envs\\tensorflow\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功加载函数\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "import matplotlib.pylab as plt\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW,AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#!nvidia-smi\n",
    "#pip install matplotlib==3.3.3 -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "\n",
    "#超参数\n",
    "SEED = 123\n",
    "BATCH_SIZE = 2\n",
    "learning_rate = 2e-5#0.00002可设置在0.001~0.0001之间 default=2e-5\n",
    "weight_decay = 1e-2#权重衰减项，防止过拟合的一个参数。在损失函数中，weight decay 是放在正则项前面的一个系数，正则项一般指示模型的复杂度，\n",
    "#所以weight decay的作用是调节模型复杂度对损失函数的影响，若weight_decay很大，则复杂的模型损失函数的值也就大#1e-2\n",
    "epsilon = 1e-8#将小浮点数添加到方差中，避免除以0\n",
    "epochs = 5\n",
    "\n",
    "data_dir = './data/'\n",
    "filename = 'sentiment_classification.h5'\n",
    "new_path = './models/xlnetmid'\n",
    "model_path = './chinese_xlnet_mid_pytorch'\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "\n",
    "\n",
    "#读取文件\n",
    "def print_df_stats(df,label=None):\n",
    "    if label:\n",
    "        print(label)\n",
    "    print(\"Shape\", df.shape)\n",
    "    print(\"Columns\", df.columns)\n",
    "    print(df.groupby(\"Score\").count())\n",
    "    print(\"\")\n",
    "\n",
    "\n",
    "def readFile(predict=False):\n",
    "    df = pd.read_hdf(data_dir + filename,index=False)\n",
    "    df.columns = [\"Text\",\"newscode\",\"typecode\",\"classification\",\"Score\"]#rename columns\n",
    "    df1 = df[df['Score']!=1]\n",
    "    df2 = df[df['Score']==1]\n",
    "    df3 = df2.sample(frac=0.89673059,replace=False,random_state=666,axis=0)\n",
    "    df4 = pd.concat([df1,df3])\n",
    "    df = df4.sample(frac=1,random_state=666,axis=0)#抽样-打乱顺序\n",
    "    df.reset_index(drop=True,inplace=True)\n",
    "    if not predict:\n",
    "        print_df_stats(df,\"Training Data\")\n",
    "    return df\n",
    "\n",
    "# 将每一句转成数字 （大于125做截断，小于125做 Padding，加上首位两个标识，长度总共等于128）\n",
    "def convert_text_to_token(tokenizer, sentence, limit_size = 125):\n",
    "    tokens = tokenizer.encode(sentence[:limit_size])       # 直接截断\n",
    "    if len(tokens) < limit_size + 3:                       # 补齐（pad的索引号就是0）\n",
    "        tokens.extend([0] * (limit_size + 3 - len(tokens)))\n",
    "    return tokens\n",
    "\n",
    "#attention_masks, 在一个文本中，如果是PAD符号则是0，否则就是1\n",
    "# 建立mask\n",
    "def attention_masks(input_ids):\n",
    "    atten_masks = []\n",
    "    for seq in input_ids:                       # [10000, 128]\n",
    "        seq_mask = [float(i > 0) for i in seq]  # PAD: 0; 否则: 1\n",
    "        atten_masks.append(seq_mask)\n",
    "    return atten_masks\n",
    "\n",
    "\n",
    "#计算模型运行时间\n",
    "import time\n",
    "import datetime\n",
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round(elapsed))\n",
    "    return str(datetime.timedelta(seconds = elapsed_rounded)) # 返回 hh:mm:ss 形式的时间\n",
    "\n",
    "#训练模型\n",
    "def train(model, optimizer):\n",
    "    torch.cuda.empty_cache()#清理内存\n",
    "    t0 = time.time()\n",
    "    avg_loss, avg_acc = [],[]\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # 每隔40个batch 输出一下所用时间.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        b_input_ids, b_input_mask, b_labels = batch[0].long().to(device), batch[1].long().to(device), batch[2].long().to(device)\n",
    "        output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "        loss, logits = output[0], output[1]      # loss: 损失, logits: predict\n",
    "\n",
    "        avg_loss.append(loss.item())\n",
    "\n",
    "        acc = binary_acc1(logits, b_labels)       # (predict, label)\n",
    "        avg_acc.append(acc)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(), 1.0) # 大于1的梯度将其设为1.0, 以防梯度爆炸\n",
    "        optimizer.step()                         # 更新模型参数\n",
    "        scheduler.step()                         # 更新learning rate\n",
    "\n",
    "    avg_acc = np.array(avg_acc).mean()\n",
    "    avg_loss = np.array(avg_loss).mean()\n",
    "    return avg_loss, avg_acc\n",
    "\n",
    "#模型准确率\n",
    "def binary_acc1(preds,labels): # preds.shape = [16, 2] labels.shape = [16, 1]\n",
    "    # torch.max: [0]为最大值, [1]为最大值索引\n",
    "    correct = torch.eq(torch.max(preds, dim=1)[1], labels.flatten()).float()\n",
    "    #对两个张量Tensor进行逐元素的比较，若相同位置的两个元素相同，则返回1；若不同，返回0\n",
    "    acc = correct.sum().item() / len(correct)\n",
    "    return acc\n",
    "#召回率，精确率\n",
    "def binary_acc(preds,labels,label_task): # preds.shape = [16, 2] labels.shape = [16, 1]\n",
    "    # torch.max: [0]为最大值, [1]为最大值索引\n",
    "    correct = torch.eq(torch.max(preds, dim=1)[1], labels.flatten()).float()\n",
    "    #对两个张量Tensor进行逐元素的比较，若相同位置的两个元素相同，则返回1；若不同，返回0\n",
    "    #可以简化为整个混淆矩阵，然后提数就ok\n",
    "    label_task = torch.tensor(label_task)\n",
    "    b_label_task = label_task.to(device)\n",
    "    num_predicts =torch.max(preds,dimm=1)[1]\n",
    "    num_labels = labels.flatten()\n",
    "    n = len(num_labels)\n",
    "    positive_count,true_count,tp_count = 0,0,0\n",
    "    for i in range(n):\n",
    "        if num_labels[i]==b_label_task:\n",
    "            true_count+=1\n",
    "            if correct[i]==1:\n",
    "                tp_count+=1\n",
    "        if num_predicts[i]==b_label_task:\n",
    "            positive_count+=1\n",
    "    return positive_count,true_count,tp_count\n",
    "    \n",
    "\n",
    "from sklearn.metrics import f1_score,recall_score,precision_recall_fscore_support\n",
    "import sklearn\n",
    "#评估模型\n",
    "def evaluate(model):\n",
    "    torch.cuda.empty_cache()#清理内存\n",
    "    avg_acc = []\n",
    "    model.eval()         # 表示进入测试模式\n",
    "    #统计召回率，精确率\n",
    "    neg_pcnt,neu_pcnt,pos_pcnt = epsilon,epsilon,epsilon#positive count\n",
    "    neg_tcnt,neu_tcnt,pos_tcnt = epsilon,epsilon,epsilon#true count\n",
    "    neg_tpcnt,neu_tpcnt,pos_tpcnt = 0,0,0#tp count\n",
    "    with torch.no_grad():\n",
    "        for batch in test_dataloader:\n",
    "            b_input_ids, b_input_mask, b_labels = batch[0].long().to(device), batch[1].long().to(device), batch[2].long().to(device)\n",
    "            output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "            acc = binary_acc1(output[0], b_labels)\n",
    "            avg_acc.append(acc)\n",
    "            #统计召回率，精确率\n",
    "            neg_pcnt_step,neg_tcnt_step,neg_tpcnt_step = binary_acc(output[0],b_labels,0)\n",
    "            neu_pcnt_step,neu_tcnt_step,neu_tpcnt_step = binary_acc(output[0],b_labels,1)\n",
    "            neg_tpcnt+=neg_tpcnt_step\n",
    "            neg_pcnt+=neg_pcnt_step\n",
    "            neg_tcnt+=neg_tcnt_step\n",
    "            neu_tpcnt+=neu_tpcnt_step\n",
    "            neu_pcnt+=neu_pcnt_step\n",
    "            neu_tcnt+=neu_tcnt_step\n",
    "            \n",
    "    avg_acc = np.array(avg_acc).mean()#列表变数组并取平均\n",
    "    #统计召回率recall=真正类/实际正类\n",
    "    neg_rec = neg_tpcnt/neg_tcnt\n",
    "    neu_rec = neu_tpcnt/neu_tcnt\n",
    "    #精确率precision=真正类/预测正类\n",
    "    neg_pre = neg_tpcnt/neg_pcnt\n",
    "    neu_pre = neu_tpcnt/neu_pcnt\n",
    "    return neg_rec,neu_rec,neg_pre,neu_pre,avg_acc\n",
    "\n",
    "#预测\n",
    "def predict(sen):\n",
    "\n",
    "    input_id = convert_text_to_token(tokenizer, sen)\n",
    "    input_token =  torch.tensor(input_id).long().to(device)            #torch.Size([128])\n",
    "\n",
    "    atten_mask = [float(i>0) for i in input_id]\n",
    "    attention_token = torch.tensor(atten_mask).long().to(device)       #torch.Size([128])\n",
    "\n",
    "    output = model(input_token.view(1, -1), token_type_ids=None, attention_mask=attention_token.view(1, -1))     #torch.Size([128])->torch.Size([1, 128])否则会报错\n",
    "    print(output[0])#置信度\n",
    "    return torch.max(output[0], dim=1)[1]\n",
    "\n",
    "#创建目录并保存新模型\n",
    "from transformers import WEIGHTS_NAME, CONFIG_NAME\n",
    "import os\n",
    "def createpath(path):\n",
    "    isExists = os.path.exists(path)\n",
    "    if not isExists:\n",
    "        os.makerdirs(path)\n",
    "        print(\"创建目录：\",path)\n",
    "\n",
    "def savemodel(path):\n",
    "    output_dir = path\n",
    "    output_model_file = os.path.join(output_dir,WEIGHTS_NAME)\n",
    "    output_config_file = os.path.join(output_dir,CONFIG_NAME)\n",
    "    torch.save(model.state_dict(),output_model_file)\n",
    "    model.config.to_json_file(output_config_file)\n",
    "    tokenizer.save_vocabulary(output_dir)\n",
    "    print('模型保存在：',output_dir)\n",
    "\n",
    "print('成功加载函数')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9d02d57",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Requirement already satisfied: transformers==4.17.0 in c:\\users\\siger\\.conda\\envs\\tensorflow\\lib\\site-packages (4.17.0)\n",
      "Collecting sentencepiece==0.1.96\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/01/21/b78bb71b7fbab906eb1d10f67d1ba69761892016cf13c4f0c5dde123bb07/sentencepiece-0.1.96-cp37-cp37m-win_amd64.whl (1.1 MB)\n",
      "     ---------------------------------------- 1.1/1.1 MB 1.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\siger\\appdata\\roaming\\python\\python37\\site-packages (from transformers==4.17.0) (21.3)\n",
      "Requirement already satisfied: requests in c:\\users\\siger\\.conda\\envs\\tensorflow\\lib\\site-packages (from transformers==4.17.0) (2.28.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\siger\\.conda\\envs\\tensorflow\\lib\\site-packages (from transformers==4.17.0) (1.21.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in c:\\users\\siger\\.conda\\envs\\tensorflow\\lib\\site-packages (from transformers==4.17.0) (0.11.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in c:\\users\\siger\\.conda\\envs\\tensorflow\\lib\\site-packages (from transformers==4.17.0) (0.13.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\siger\\.conda\\envs\\tensorflow\\lib\\site-packages (from transformers==4.17.0) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\siger\\.conda\\envs\\tensorflow\\lib\\site-packages (from transformers==4.17.0) (4.64.1)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\siger\\.conda\\envs\\tensorflow\\lib\\site-packages (from transformers==4.17.0) (4.11.3)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\siger\\.conda\\envs\\tensorflow\\lib\\site-packages (from transformers==4.17.0) (0.0.53)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\siger\\.conda\\envs\\tensorflow\\lib\\site-packages (from transformers==4.17.0) (2022.10.31)\n",
      "Requirement already satisfied: filelock in c:\\users\\siger\\.conda\\envs\\tensorflow\\lib\\site-packages (from transformers==4.17.0) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\siger\\.conda\\envs\\tensorflow\\lib\\site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.17.0) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\siger\\appdata\\roaming\\python\\python37\\site-packages (from packaging>=20.0->transformers==4.17.0) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\siger\\appdata\\roaming\\python\\python37\\site-packages (from tqdm>=4.27->transformers==4.17.0) (0.4.6)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\siger\\.conda\\envs\\tensorflow\\lib\\site-packages (from importlib-metadata->transformers==4.17.0) (3.8.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\siger\\.conda\\envs\\tensorflow\\lib\\site-packages (from requests->transformers==4.17.0) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\siger\\.conda\\envs\\tensorflow\\lib\\site-packages (from requests->transformers==4.17.0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\siger\\.conda\\envs\\tensorflow\\lib\\site-packages (from requests->transformers==4.17.0) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\siger\\.conda\\envs\\tensorflow\\lib\\site-packages (from requests->transformers==4.17.0) (2022.9.24)\n",
      "Requirement already satisfied: click in c:\\users\\siger\\.conda\\envs\\tensorflow\\lib\\site-packages (from sacremoses->transformers==4.17.0) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\siger\\.conda\\envs\\tensorflow\\lib\\site-packages (from sacremoses->transformers==4.17.0) (1.2.0)\n",
      "Requirement already satisfied: six in c:\\users\\siger\\.conda\\envs\\tensorflow\\lib\\site-packages (from sacremoses->transformers==4.17.0) (1.16.0)\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.96\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers==4.17.0 sentencepiece==0.1.96\n",
    "# !pip install tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5922926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_hdf(data_dir + filename,index=False)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56aee764",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f851e250",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data\n",
      "Shape (254476, 5)\n",
      "Columns Index(['Text', 'newscode', 'typecode', 'classification', 'Score'], dtype='object')\n",
      "         Text  newscode  typecode  classification\n",
      "Score                                            \n",
      "0      127238    127238    127238          127238\n",
      "1      127238    127238    127238          127238\n",
      "\n",
      "Training Data\n",
      "Shape (254476, 5)\n",
      "Columns Index(['Text', 'newscode', 'typecode', 'classification', 'Score'], dtype='object')\n",
      "         Text  newscode  typecode  classification\n",
      "Score                                            \n",
      "0      127238    127238    127238          127238\n",
      "1      127238    127238    127238          127238\n",
      "\n",
      "torch.Size([254476, 128])\n",
      "torch.Size([254476, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ./chinese_xlnet_mid_pytorch were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at ./chinese_xlnet_mid_pytorch and are newly initialized: ['logits_proj.weight', 'sequence_summary.summary.weight', 'sequence_summary.summary.bias', 'logits_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training steps 的数量: 101790\n",
      "---开始训练---\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 4.00 GiB total capacity; 3.12 GiB already allocated; 0 bytes free; 3.44 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17372\\3326665907.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[0mbest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epoch={},训练准确率={}，损失={}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17372\\80348591.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, optimizer)\u001b[0m\n\u001b[0;32m    105\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m         \u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# 大于1的梯度将其设为1.0, 以防梯度爆炸\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m                         \u001b[1;31m# 更新模型参数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    108\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m                         \u001b[1;31m# 更新learning rate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\torch\\optim\\lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[1;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tensorflow\\lib\\site-packages\\transformers\\optimization.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    346\u001b[0m                     \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"step\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m                     \u001b[1;31m# Exponential moving average of gradient values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m                     \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"exp_avg\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m                     \u001b[1;31m# Exponential moving average of squared gradient values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m                     \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"exp_avg_sq\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 4.00 GiB total capacity; 3.12 GiB already allocated; 0 bytes free; 3.44 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "#train and test\n",
    "\n",
    "#读x和y\n",
    "sentences = readFile().iloc[:,0].tolist()\n",
    "targets = readFile().iloc[:,4].tolist()\n",
    "\n",
    "#读取Tokenizer分词器\n",
    "model_name = model_path\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "input_ids = [convert_text_to_token(tokenizer, sen) for sen in sentences]\n",
    "input_tokens = torch.tensor(input_ids)\n",
    "print(input_tokens.shape)              # torch.Size([10000, 128])\n",
    "\n",
    "total_targets = torch.tensor(targets)\n",
    "atten_masks = attention_masks(input_ids)\n",
    "attention_tokens = torch.tensor(atten_masks)\n",
    "print(attention_tokens.shape)                   # torch.Size([10000, 128])\n",
    "\n",
    "#划分训练集和测试集\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_inputs, test_inputs, train_labels, test_labels = train_test_split(input_tokens, total_targets,\n",
    "                                                                        random_state=666, test_size=0.2)\n",
    "train_masks, test_masks, _, _ = train_test_split(attention_tokens, input_tokens,\n",
    "                                                 random_state=666, test_size=0.2)\n",
    "\n",
    "\n",
    "#创建DataLoader，用来取出一个batch的数据\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE,drop_last=True)\n",
    "\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_sampler = RandomSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE,drop_last=True)\n",
    "\n",
    "\n",
    "# #查看一下train_dataloader的内容：\n",
    "# for i, (train, mask, label) in enumerate(train_dataloader):\n",
    "#     # torch.Size([16, 128]) torch.Size([16, 128]) torch.Size([16, 1])\n",
    "#     print(train.shape, mask.shape, label.shape)\n",
    "#     break\n",
    "\n",
    "# print('len(train_dataloader) = ', len(train_dataloader))    # 500\n",
    "\n",
    "#创建模型\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels = 2) # num_labels表示2个分类,好评和差评\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "#定义优化器\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "# 判断optimizer_param中所有的参数。如果不在no_decay中，则进行权重衰减;如果在no_decay中，则不进行权重衰减\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params' : [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay' : weight_decay\n",
    "    },\n",
    "    {'params' : [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay' : 0.0\n",
    "    }\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr = learning_rate, eps = epsilon)\n",
    "\n",
    "#学习率预热，训练时先从小的学习率开始训练\n",
    "# training steps 的数量: [number of batches] x [number of epochs].\n",
    "print(\"training steps 的数量:\",len(train_dataloader))\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "warmup_proportion = 0.1\n",
    "#不知道这步合理不合理，还是直接用0.1？需要回顾\n",
    "warmup_steps = int(total_steps*warmup_proportion)\n",
    "# 设计 learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = warmup_steps,\n",
    "                                            num_training_steps = total_steps)\n",
    "\n",
    "\n",
    "#运行训练模型和评估模型\n",
    "print('---开始训练---')\n",
    "best_acc = 0\n",
    "for epoch in range(1,epochs+1):\n",
    "    train_loss, train_acc = train(model, optimizer)\n",
    "    print('epoch={},训练准确率={}，损失={}'.format(epoch, train_acc, train_loss))\n",
    "\n",
    "    neg_rec,neu_rec,neg_pre,neu_pre,test_acc = evaluate(model)\n",
    "    print(\"epoch={},测试准确率={}\".format(epoch, test_acc))\n",
    "    print(\"epoch={},负面集测试召回率={}，精确率={}\".format(epoch,neg_rec,neg_pre))\n",
    "    print(\"epoch={},正面集测试召回率={}，精确率={}\".format(epoch,neu_rec,neu_pre))\n",
    "    \n",
    "    #保存最好模型\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        print(\"正在保存模型...\")\n",
    "        createpath(new_path)\n",
    "        savemodel(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f497a5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载经过微调的模型进行推理\n",
    "#加载模型\n",
    "model_path = './models/xlnetmid'\n",
    "num = 50\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path, num_labels = 2) # num_labels表示2个分类,好评和差评\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "#读文件\n",
    "sentences = readFile(predict=True).iloc[:,0].tolist()\n",
    "targets = readFile(predict=True).iloc[:,4].tolist()\n",
    "dfp1 = pd.DataFrame(sentences)\n",
    "dfp2 = pd.DataFrame(targets)\n",
    "res,count = [],0\n",
    "\n",
    "for sen in sentences:\n",
    "    label = predict(sen)\n",
    "    res.append(int(label[0].item()))\n",
    "    count+=1\n",
    "    if count>=num:break\n",
    "\n",
    "dfp3 = pd.DataFrame(res)\n",
    "dfp = pd.concat([dfp1,dfp2,dfp3],axis=1)\n",
    "dfp.columns = [\"文本\",\"标签\",\"预测\"]#rename columns\n",
    "dfp = dfp.fillna(999)\n",
    "dfp[\"预测\"].astype(\"int64\")\n",
    "dfp.head(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628c6e75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6d49ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be45188a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c765f682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a01af2c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                            VersionNote: you may need to restart the kernel to use updated packages.\n",
      "---------------------------------- --------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -5py (c:\\users\\siger\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -5py (c:\\users\\siger\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -5py (c:\\users\\siger\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -5py (c:\\users\\siger\\anaconda3\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py                            1.0.0\n",
      "aiohttp                            3.8.1\n",
      "aiosignal                          1.2.0\n",
      "alabaster                          0.7.12\n",
      "anaconda-client                    1.9.0\n",
      "anaconda-navigator                 2.1.4\n",
      "anaconda-project                   0.10.2\n",
      "anyio                              3.5.0\n",
      "appdirs                            1.4.4\n",
      "argcomplete                        1.12.3\n",
      "argh                               0.26.2\n",
      "argon2-cffi                        21.3.0\n",
      "argon2-cffi-bindings               21.2.0\n",
      "arrow                              1.2.2\n",
      "asn1crypto                         1.4.0\n",
      "astor                              0.8.1\n",
      "astroid                            2.6.6\n",
      "astropy                            4.3.1\n",
      "astunparse                         1.6.3\n",
      "async-generator                    1.10\n",
      "async-timeout                      4.0.1\n",
      "asynctest                          0.13.0\n",
      "atomicwrites                       1.4.0\n",
      "attrs                              21.4.0\n",
      "Automat                            20.2.0\n",
      "autopep8                           1.6.0\n",
      "Babel                              2.9.1\n",
      "backcall                           0.2.0\n",
      "backports.functools-lru-cache      1.6.4\n",
      "backports.shutil-get-terminal-size 1.0.0\n",
      "backports.tempfile                 1.0\n",
      "backports.weakref                  1.0.post1\n",
      "bcrypt                             3.2.0\n",
      "beautifulsoup4                     4.10.0\n",
      "binaryornot                        0.4.4\n",
      "bitarray                           2.4.1\n",
      "bkcharts                           0.2\n",
      "black                              19.10b0\n",
      "bleach                             4.1.0\n",
      "blinker                            1.4\n",
      "blis                               0.2.4\n",
      "bokeh                              2.4.2\n",
      "boto                               2.49.0\n",
      "Bottleneck                         1.3.4\n",
      "brotlipy                           0.7.0\n",
      "cached-property                    1.5.2\n",
      "cachetools                         4.2.2\n",
      "certifi                            2021.10.8\n",
      "cffi                               1.15.0\n",
      "chardet                            4.0.0\n",
      "charset-normalizer                 2.0.4\n",
      "click                              8.0.4\n",
      "cloudpickle                        2.0.0\n",
      "clyent                             1.2.2\n",
      "colorama                           0.4.4\n",
      "comtypes                           1.1.10\n",
      "conda                              4.12.0\n",
      "conda-build                        3.21.8\n",
      "conda-content-trust                0+unknown\n",
      "conda-pack                         0.6.0\n",
      "conda-package-handling             1.8.1\n",
      "conda-repo-cli                     1.0.4\n",
      "conda-token                        0.3.0\n",
      "conda-verify                       3.4.2\n",
      "constantly                         15.1.0\n",
      "contextlib2                        0.6.0.post1\n",
      "cookiecutter                       1.7.3\n",
      "cryptography                       3.4.8\n",
      "cssselect                          1.1.0\n",
      "cycler                             0.11.0\n",
      "cymem                              2.0.6\n",
      "Cython                             0.29.28\n",
      "cytoolz                            0.11.0\n",
      "daal4py                            2021.5.0\n",
      "dask                               2021.10.0\n",
      "debugpy                            1.5.1\n",
      "decorator                          5.1.1\n",
      "defusedxml                         0.7.1\n",
      "diff-match-patch                   20200713\n",
      "dill                               0.3.4\n",
      "distlib                            0.3.4\n",
      "distributed                        2021.10.0\n",
      "docutils                           0.17.1\n",
      "entrypoints                        0.3\n",
      "et-xmlfile                         1.1.0\n",
      "fast-histogram                     0.9\n",
      "fastcache                          1.1.0\n",
      "fastjsonschema                     2.15.1\n",
      "filelock                           3.6.0\n",
      "flake8                             3.9.2\n",
      "Flask                              1.1.2\n",
      "flatbuffers                        2.0\n",
      "fonttools                          4.25.0\n",
      "frozenlist                         1.2.0\n",
      "fsspec                             2022.2.0\n",
      "future                             0.18.2\n",
      "gast                               0.2.2\n",
      "gevent                             21.8.0\n",
      "glob2                              0.7\n",
      "glue-core                          0.15.6\n",
      "glue-vispy-viewers                 0.12.2\n",
      "glueviz                            1.0.0\n",
      "google-auth                        1.35.0\n",
      "google-auth-oauthlib               0.4.4\n",
      "google-pasta                       0.2.0\n",
      "greenlet                           1.1.1\n",
      "grpcio                             1.42.0\n",
      "h5py                               3.6.0\n",
      "HeapDict                           1.0.1\n",
      "html5lib                           1.1\n",
      "huggingface-hub                    0.6.0\n",
      "hyperlink                          21.0.0\n",
      "idna                               3.3\n",
      "imagecodecs                        2021.8.26\n",
      "imageio                            2.9.0\n",
      "imagesize                          1.3.0\n",
      "imbalanced-learn                   0.6.2\n",
      "imblearn                           0.0\n",
      "importlib-metadata                 4.11.3\n",
      "incremental                        21.3.0\n",
      "inflection                         0.5.1\n",
      "iniconfig                          1.1.1\n",
      "intervaltree                       3.1.0\n",
      "ipykernel                          6.9.1\n",
      "ipython                            7.31.1\n",
      "ipython-genutils                   0.2.0\n",
      "ipywidgets                         7.6.5\n",
      "isort                              5.9.3\n",
      "itemadapter                        0.3.0\n",
      "itemloaders                        1.0.4\n",
      "itsdangerous                       2.0.1\n",
      "jdcal                              1.4.1\n",
      "jedi                               0.18.1\n",
      "Jinja2                             2.11.3\n",
      "jinja2-time                        0.2.0\n",
      "jmespath                           0.10.0\n",
      "joblib                             1.1.0\n",
      "json5                              0.9.6\n",
      "jsonschema                         3.2.0\n",
      "jupyter                            1.0.0\n",
      "jupyter-client                     6.1.12\n",
      "jupyter-console                    6.4.0\n",
      "jupyter-contrib-core               0.3.3\n",
      "jupyter-contrib-nbextensions       0.5.1\n",
      "jupyter-core                       4.9.2\n",
      "jupyter-highlight-selected-word    0.2.0\n",
      "jupyter-latex-envs                 1.4.6\n",
      "jupyter-nbextensions-configurator  0.4.1\n",
      "jupyter-server                     1.13.5\n",
      "jupyterlab                         3.3.2\n",
      "jupyterlab-pygments                0.1.2\n",
      "jupyterlab-server                  2.10.3\n",
      "jupyterlab-widgets                 1.0.0\n",
      "Keras                              2.3.1\n",
      "Keras-Applications                 1.0.8\n",
      "Keras-Preprocessing                1.1.2\n",
      "keyring                            23.4.0\n",
      "kiwisolver                         1.3.2\n",
      "lazy-object-proxy                  1.6.0\n",
      "libarchive-c                       2.9\n",
      "libclang                           14.0.1\n",
      "linearmodels                       4.14\n",
      "llvmlite                           0.36.0\n",
      "locket                             0.2.1\n",
      "lxml                               4.8.0\n",
      "Markdown                           3.3.4\n",
      "MarkupSafe                         2.0.1\n",
      "matplotlib                         3.5.1\n",
      "matplotlib-inline                  0.1.2\n",
      "mccabe                             0.6.1\n",
      "menuinst                           1.4.18\n",
      "mistune                            0.8.4\n",
      "mkl-fft                            1.3.1\n",
      "mkl-random                         1.2.2\n",
      "mkl-service                        2.4.0\n",
      "mock                               4.0.3\n",
      "more-itertools                     8.12.0\n",
      "mpl-scatter-density                0.7\n",
      "mpmath                             1.2.1\n",
      "msgpack                            1.0.2\n",
      "multidict                          5.1.0\n",
      "multipledispatch                   0.6.0\n",
      "munkres                            1.1.4\n",
      "murmurhash                         1.0.7\n",
      "mypy-extensions                    0.4.3\n",
      "navigator-updater                  0.2.1\n",
      "nbclassic                          0.3.5\n",
      "nbclient                           0.5.11\n",
      "nbconvert                          6.4.4\n",
      "nbformat                           5.3.0\n",
      "nest-asyncio                       1.5.5\n",
      "networkx                           2.6.3\n",
      "nltk                               3.7\n",
      "nose                               1.3.7\n",
      "notebook                           6.4.8\n",
      "numba                              0.53.0\n",
      "numexpr                            2.8.1\n",
      "numpy                              1.21.5\n",
      "numpydoc                           1.2\n",
      "oauthlib                           3.2.0\n",
      "olefile                            0.46\n",
      "openpyxl                           3.0.9\n",
      "opt-einsum                         3.3.0\n",
      "packaging                          21.3\n",
      "pandas                             1.3.5\n",
      "pandocfilters                      1.5.0\n",
      "paramiko                           2.8.1\n",
      "parsel                             1.6.0\n",
      "parso                              0.8.3\n",
      "partd                              1.2.0\n",
      "path                               16.2.0\n",
      "pathlib2                           2.3.6\n",
      "pathspec                           0.7.0\n",
      "patsy                              0.5.2\n",
      "pep8                               1.7.1\n",
      "pexpect                            4.8.0\n",
      "pickleshare                        0.7.5\n",
      "Pillow                             9.0.1\n",
      "pip                                21.2.4\n",
      "pkginfo                            1.8.2\n",
      "plac                               0.9.6\n",
      "platformdirs                       2.5.2\n",
      "plotly                             5.6.0\n",
      "pluggy                             1.0.0\n",
      "ply                                3.11\n",
      "poyo                               0.5.0\n",
      "preshed                            2.0.1\n",
      "prometheus-client                  0.13.1\n",
      "prompt-toolkit                     3.0.20\n",
      "property-cached                    1.6.3\n",
      "Protego                            0.1.16\n",
      "protobuf                           3.19.1\n",
      "psutil                             5.8.0\n",
      "ptyprocess                         0.7.0\n",
      "py                                 1.11.0\n",
      "pyasn1                             0.4.8\n",
      "pyasn1-modules                     0.2.8\n",
      "pycodestyle                        2.7.0\n",
      "pycosat                            0.6.3\n",
      "pycparser                          2.21\n",
      "pycrypto                           2.6.1\n",
      "pycurl                             7.44.1\n",
      "PyDispatcher                       2.0.5\n",
      "pydocstyle                         6.1.1\n",
      "pyerfa                             2.0.0\n",
      "pyflakes                           2.3.1\n",
      "Pygments                           2.11.2\n",
      "PyHamcrest                         2.0.2\n",
      "PyJWT                              2.1.0\n",
      "pylint                             2.9.6\n",
      "pyls-spyder                        0.4.0\n",
      "PyNaCl                             1.4.0\n",
      "pyodbc                             4.0.32\n",
      "PyOpenGL                           3.1.1a1\n",
      "pyOpenSSL                          21.0.0\n",
      "pyparsing                          3.0.4\n",
      "pyreadline                         2.1\n",
      "pyrsistent                         0.18.0\n",
      "PySocks                            1.7.1\n",
      "pytest                             7.1.1\n",
      "python-dateutil                    2.8.2\n",
      "python-lsp-black                   1.0.0\n",
      "python-lsp-jsonrpc                 1.0.0\n",
      "python-lsp-server                  1.2.4\n",
      "python-slugify                     5.0.2\n",
      "pytz                               2021.3\n",
      "PyWavelets                         1.3.0\n",
      "pywin32                            302\n",
      "pywin32-ctypes                     0.2.0\n",
      "pywinpty                           2.0.2\n",
      "PyYAML                             6.0\n",
      "pyzmq                              22.3.0\n",
      "QDarkStyle                         3.0.2\n",
      "qstylizer                          0.1.10\n",
      "QtAwesome                          1.0.3\n",
      "qtconsole                          5.3.0\n",
      "QtPy                               2.0.1\n",
      "queuelib                           1.5.0\n",
      "regex                              2022.3.15\n",
      "requests                           2.27.1\n",
      "requests-file                      1.5.1\n",
      "requests-oauthlib                  1.3.0\n",
      "rope                               0.22.0\n",
      "rsa                                4.7.2\n",
      "Rtree                              0.9.7\n",
      "ruamel-yaml-conda                  0.15.100\n",
      "scikit-image                       0.19.2\n",
      "scikit-learn                       1.0.2\n",
      "scikit-learn-intelex               2021.20220215.153008\n",
      "scipy                              1.4.1\n",
      "Scrapy                             2.6.1\n",
      "seaborn                            0.11.2\n",
      "Send2Trash                         1.8.0\n",
      "sentencepiece                      0.1.96\n",
      "service-identity                   18.1.0\n",
      "setuptools                         61.2.0\n",
      "simplegeneric                      0.8.1\n",
      "singledispatch                     3.7.0\n",
      "sip                                4.19.13\n",
      "six                                1.16.0\n",
      "sklearn                            0.0\n",
      "sniffio                            1.2.0\n",
      "snowballstemmer                    2.2.0\n",
      "sortedcollections                  2.1.0\n",
      "sortedcontainers                   2.4.0\n",
      "soupsieve                          2.3.1\n",
      "spacy                              2.1.8\n",
      "Sphinx                             4.4.0\n",
      "sphinxcontrib-applehelp            1.0.2\n",
      "sphinxcontrib-devhelp              1.0.2\n",
      "sphinxcontrib-htmlhelp             2.0.0\n",
      "sphinxcontrib-jsmath               1.0.1\n",
      "sphinxcontrib-qthelp               1.0.3\n",
      "sphinxcontrib-serializinghtml      1.1.5\n",
      "sphinxcontrib-websupport           1.2.4\n",
      "spyder                             5.1.5\n",
      "spyder-kernels                     2.1.3\n",
      "SQLAlchemy                         1.4.32\n",
      "srsly                              1.0.5\n",
      "statsmodels                        0.13.2\n",
      "sympy                              1.10.1\n",
      "tables                             3.4.4\n",
      "TBB                                0.2\n",
      "tblib                              1.7.0\n",
      "tenacity                           8.0.1\n",
      "tensorboard                        2.0.2\n",
      "tensorboard-data-server            0.6.1\n",
      "tensorboard-plugin-wit             1.6.0\n",
      "tensorflow                         2.0.0\n",
      "tensorflow-estimator               2.0.1\n",
      "tensorflow-io-gcs-filesystem       0.26.0\n",
      "termcolor                          1.1.0\n",
      "terminado                          0.13.1\n",
      "testpath                           0.5.0\n",
      "text-unidecode                     1.3\n",
      "textdistance                       4.2.1\n",
      "tf-estimator-nightly               2.8.0.dev2021122109\n",
      "thinc                              7.0.8\n",
      "threadpoolctl                      2.2.0\n",
      "three-merge                        0.1.1\n",
      "tifffile                           2021.7.2\n",
      "tinycss                            0.4\n",
      "tldextract                         3.2.0\n",
      "tokenizers                         0.12.1\n",
      "toml                               0.10.2\n",
      "tomli                              1.2.2\n",
      "toolz                              0.11.2\n",
      "torch                              1.8.0\n",
      "torchtext                          0.9.0\n",
      "torchvision                        0.5.0\n",
      "tornado                            6.1\n",
      "tqdm                               4.63.0\n",
      "traitlets                          5.1.1\n",
      "transformers                       4.19.2\n",
      "Twisted                            22.2.0\n",
      "twisted-iocpsupport                1.0.2\n",
      "typed-ast                          1.4.3\n",
      "typing_extensions                  4.1.1\n",
      "ujson                              5.1.0\n",
      "unicodecsv                         0.14.1\n",
      "Unidecode                          1.2.0\n",
      "urllib3                            1.26.8\n",
      "virtualenv                         20.14.1\n",
      "w3lib                              1.21.0\n",
      "wasabi                             0.9.1\n",
      "watchdog                           2.1.6\n",
      "wcwidth                            0.2.5\n",
      "webencodings                       0.5.1\n",
      "websocket-client                   0.58.0\n",
      "Werkzeug                           2.1.2\n",
      "wheel                              0.37.1\n",
      "whichcraft                         0.6.1\n",
      "widgetsnbextension                 3.5.2\n",
      "win-inet-pton                      1.1.0\n",
      "win-unicode-console                0.5\n",
      "wincertstore                       0.2\n",
      "wrapt                              1.12.1\n",
      "xgboost                            1.0.2\n",
      "xlrd                               2.0.1\n",
      "XlsxWriter                         3.0.3\n",
      "xlwings                            0.24.9\n",
      "xlwt                               1.3.0\n",
      "yapf                               0.31.0\n",
      "yarl                               1.6.3\n",
      "zict                               2.0.0\n",
      "zipp                               3.7.0\n",
      "zope.event                         4.5.0\n",
      "zope.interface                     5.4.0\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b5123a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-tensorflow] *",
   "language": "python",
   "name": "conda-env-.conda-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
